{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb8692-0c32-4525-82fe-1c6cfb049dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d28d69-603d-4ce8-97a7-b0bc9702e9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f41855-203b-42b1-b2fc-b22b47714f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.models import Model\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "PATH=\".\"\n",
    "train_dir = os.path.join(PATH, 'train_50')\n",
    "validation_dir = os.path.join(PATH, 'test_50')\n",
    "\n",
    "train_dataset = image_dataset_from_directory(train_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=image_size)\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=image_size)\n",
    "##preprocessing\n",
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "train_samples = 1400\n",
    "validation_samples = 420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f99956-9cab-4781-8b7b-ff40fb8605ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "train_generator_bottleneck = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "validation_generator_bottleneck = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa2b125-0f1f-4f8d-81a7-d414b23d7ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bottleneck_features_train = model_vgg.predict_generator(train_generator_bottleneck, train_samples // batch_size)\n",
    "np.save(open('result/bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "bottleneck_features_validation = model_vgg.predict_generator(validation_generator_bottleneck, validation_samples // batch_size)\n",
    "np.save(open('result/bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
    "\n",
    "#Now we can load it...\n",
    "train_data = np.load(open('result/bottleneck_features_train.npy', 'rb'))\n",
    "train_labels = np.array([0] * (train_samples // 2) + [1] * (train_samples // 2))\n",
    "\n",
    "validation_data = np.load(open('result/bottleneck_features_validation.npy', 'rb'))\n",
    "validation_labels = np.array([0] * (validation_samples // 2) + [1] * (validation_samples // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7987c6f3-cdf1-4877-8a18-ff9e3297b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And define and train the custom fully connected neural network :\n",
    "\n",
    "model_top = Sequential()\n",
    "model_top.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model_top.add(Dense(256, activation='relu'))\n",
    "model_top.add(Dropout(0.5))\n",
    "model_top.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_top.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_top.fit(train_data, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_data, validation_labels))\n",
    "\n",
    "model_top.save_weights('/content/drive/MyDrive/final_1/result/bottleneck_30_epochs.h5')\n",
    "\n",
    "#Bottleneck model evaluation\n",
    "#Loss and accuracy :\n",
    "model_top.evaluate(validation_data, validation_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
