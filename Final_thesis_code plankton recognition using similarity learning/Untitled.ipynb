{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f1528-e472-4f8b-ae78-5420f664a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the fourth GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5de3d-67ae-4dc4-9635-7737ff32e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-kitty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocess_functions import prepare_dataset,create_ziped_dataset1,buildDataSet,load_classes,get_train_test_dataset\n",
    "from build_network import build_network,build_model\n",
    "from utils import DrawPics,drawTriplets\n",
    "from learning_utils import compute_probs,get_batch_hard,get_batch_random,compute_dist,compute_metrics,compute_interdist,draw_interdist,draw_roc,DrawTestImage\n",
    "from keras.engine.topology import Layer\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model,normalize\n",
    "\n",
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def triplet_loss(self, inputs):\n",
    "        anchor, positive, negative = inputs\n",
    "        p_dist = K.sum(K.square(anchor-positive), axis=-1)\n",
    "        n_dist = K.sum(K.square(anchor-negative), axis=-1)\n",
    "        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "class NetworkConfig:\n",
    "\tdef __init__(self, min_samples=0):\n",
    "\t\tself.min_samples = min_samples\n",
    "\n",
    "networkConfig = NetworkConfig()\n",
    "networkConfig.model_path = None\n",
    "networkConfig.min_samples = 10\n",
    "networkConfig.data_location = \"./labeled\"\n",
    "networkConfig.extend = '.png'\n",
    "networkConfig.prepare_dir = ''\n",
    "networkConfig.prepare_num = 10\n",
    "networkConfig.prepare_test_size = 20/ float(100)\n",
    "output_dir=\".\"\n",
    "image_size = (256, 245 )\n",
    "nb_classes=44\n",
    "\n",
    "#def l2Norm(x):\n",
    " #       return  K.l2_normalize(x, axis=-1)\n",
    "#def triplet_loss(y_true, y_pred):\n",
    " #   margin = K.constant(0.02)\n",
    "  #  return K.mean(K.maximum(K.constant(0), K.square(y_pred[:,0,0]) - K.square(y_pred[:,1,0]) + margin))\n",
    "#def accuracy(y_true, y_pred):\n",
    " #   return K.mean(y_pred[:,0,0] < y_pred[:,1,0])\n",
    "#def euclidean_distance(vects):\n",
    " #   x, y = vects\n",
    "  #  return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "projectName = \"plankton_recognition_LUT\"\n",
    "project_path = './{0}/'.format(projectName)\n",
    "model_path = '../{0}/'.format(projectName)\n",
    "if not path.exists(project_path):\n",
    "    os.mkdir(project_path)\n",
    "if not path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "input_shape=IMG_SHAPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\".\"\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'test')\n",
    "\n",
    "train_dataset = image_dataset_from_directory(train_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
    "class_names = train_dataset.class_names\n",
    "class_names1 = validation_dataset.class_names\n",
    "create_ziped_dataset1(train_dataset, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "[dataset_train,dataset_test,x_train_origin,y_train_origin,x_test_origin,y_test_origin]=buildDataSet()\n",
    "print(\"Checking shapes for class 0 (train) : \",dataset_train[0].shape)\n",
    "print(\"Checking shapes for class 0 (test) : \",dataset_test[0].shape)\n",
    "print(\"Checking first samples\")\n",
    "#for i in range(19,20):\n",
    "    #DrawPics(dataset_train[i],5,template='Train {}',classnumber=i)\n",
    "    #DrawPics(dataset_test[i],5,template='Test {}',classnumber=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "from keras.applications import MobileNetV2\n",
    "base_model = MobileNetV2(input_shape=IMG_SHAPE,include_top=False, weights='imagenet')\n",
    "embeddingsize=21\n",
    "net =base_model.output\n",
    "net = tf.keras.layers.Flatten()(net) \n",
    "net = tf.keras.layers.Dropout(0.5)(net)\n",
    "net = tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=l2(1e-3), kernel_initializer='he_uniform')(net)\n",
    "net = tf.keras.layers.Dense(embeddingsize, activation=None, kernel_regularizer=l2(1e-3), kernel_initializer='he_uniform')(net)\n",
    "net = tf.keras.layers.Flatten()(net) \n",
    "\n",
    "#Force the encoding to live on the d-dimentional hypershpere\n",
    "net = tf.keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=-1))(net)\n",
    "base_model =tf.keras.Model(base_model.input, net, name='tuned_model')\n",
    "base_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "base_model = VGG16(input_shape=IMG_SHAPE,weights='imagenet', include_top=False)\n",
    "embeddingsize=44\n",
    "net =base_model.output\n",
    "net = tf.keras.layers.Dropout(0.5)(net)\n",
    "net = tf.keras.layers.Flatten()(net) \n",
    "net = tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=l2(1e-2), kernel_initializer='he_uniform')(net)\n",
    "net = tf.keras.layers.Dense(embeddingsize, activation=None, kernel_regularizer=l2(1e-2), kernel_initializer='he_uniform')(net)\n",
    "\n",
    "#Force the encoding to live on the d-dimentional hypershpere\n",
    "net = tf.keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=-1))(net)\n",
    "base_model =tf.keras.Model(base_model.input, net, name='tuned_model')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "base_model = ResNet50(weights='imagenet', include_top = False)\n",
    "embeddingsize=21\n",
    "net =base_model.output\n",
    "net = tf.keras.layers.Dropout(0.5)(net)\n",
    "net = tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=l2(1e-3), kernel_initializer='he_uniform')(net)\n",
    "net = tf.keras.layers.Dense(embeddingsize, activation=None, kernel_regularizer=l2(1e-3), kernel_initializer='he_uniform')(net)\n",
    "net = tf.keras.layers.Flatten()(net) \n",
    "\n",
    "#Force the encoding to live on the d-dimentional hypershpere\n",
    "net = tf.keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=-1))(net)\n",
    "base_model =tf.keras.Model(base_model.input, net, name='tuned_model')\n",
    "base_model.summary()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "base_model = VGG19(input_shape=IMG_SHAPE,weights='imagenet')\n",
    "base_model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "embeddingsize=21\n",
    "net =base_model.output\n",
    "net = tf.keras.layers.Dropout(0.5)(net)\n",
    "net = tf.keras.layers.Flatten()(net) \n",
    "net = tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=l2(1e-3), kernel_initializer='he_uniform')(net)\n",
    "net = tf.keras.layers.Dense(embeddingsize, activation=None, kernel_regularizer=l2(1e-3), kernel_initializer='he_uniform')(net)\n",
    "\n",
    "#Force the encoding to live on the d-dimentional hypershpere\n",
    "net = tf.keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=-1))(net)\n",
    "base_model =tf.keras.Model(base_model.input, net, name='tuned_model')\n",
    "base_model.summary()\n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 10\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardtriplets = get_batch_hard(50,1,1, base_model, dataset_train)\n",
    "print(\"Shapes in the hardbatch A:{0} P:{1} N:{2}\".format(hardtriplets[0].shape, hardtriplets[1].shape, hardtriplets[2].shape))\n",
    "#drawTriplets(hardtriplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = build_model(input_shape,base_model)\n",
    "optimizer = Adam(lr = 0.00006)\n",
    "model.compile(loss=None,optimizer=optimizer)\n",
    "#model.compile(optimizer=\"rmsprop\", loss=triplet_loss, metrics=[accuracy])\n",
    "model.summary()\n",
    "#plot_model(network_train,show_shapes=True, show_layer_names=True, to_file='02 model.png')\n",
    "print(model.metrics_names)\n",
    "n_iteration=0\n",
    "#network_train.load_weights('mnist-160k_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_every = 50 # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iter = 800# No. of training iterations\n",
    "n_val = 250 # how many one- shot tasks to validate on\n",
    "log_every = 50\n",
    "#####Testing on an untrained network\n",
    "probs,yprob = compute_probs(base_model,x_test_origin[:44,:,:,:],y_test_origin[:44])\n",
    "fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "draw_roc(fpr, tpr,thresholds,auc)\n",
    "draw_interdist(base_model,0,dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainning of the model \n",
    "def prediction1(network, x_test_origin, dataset_test, test_label,top,threshold,classindicator=-1, refidx=1,nb_test_class=21 ):\n",
    "    predicted=[]\n",
    "    _, w,h,c = dataset_test[0].shape\n",
    "    nbimages=x_test_origin.shape[0]\n",
    "    nb_display=21\n",
    "    # planton spieces/ classes \n",
    "    classes = load_classes(networkConfig.data_location, networkConfig.extend, networkConfig.min_samples)\n",
    "    #generates embedings for reference images\n",
    "    ref_images = np.zeros((nb_test_class,w,h,c))\n",
    "    for i in range(nb_test_class):\n",
    "        ref_images[i,:,:,:] = dataset_test[i][refidx,:,:,:]\n",
    "    ref_embedings = network.predict(ref_images)   \n",
    "    c=0\n",
    "    for i in range(0,nbimages):\n",
    "        #generates embedings for given images\n",
    "        image_embedings = network.predict(np.expand_dims(x_test_origin[i,:,:,:],axis=0))\n",
    "        if nbimages>1:\n",
    "            trueclass=i\n",
    "        else:\n",
    "            trueclass=classindicator\n",
    "        distdtype=[('class', int), ('dist', float)]\n",
    "        dist = np.zeros(nb_test_class, dtype=distdtype)        \n",
    "        #Compute distances\n",
    "        for ref in range(nb_test_class):\n",
    "            #Compute distance between this images and references\n",
    "            dist[ref] = (ref,compute_dist(image_embedings[:],ref_embedings[ref,:]))          \n",
    "        #sort\n",
    "        sorted_dist = np.sort(dist, order='dist')\n",
    "        found=False\n",
    "\n",
    "        for a in range(0,top):\n",
    "            if (test_label[i]==classes[sorted_dist['class'][a]]):\n",
    "                predicted.append(classes[sorted_dist['class'][a]])\n",
    "                found=True;\n",
    "                c=c+1\n",
    "                break;\n",
    "        if(found==False):\n",
    "            predicted.append(classes[sorted_dist['class'][0]])\n",
    "    \n",
    "    print(c)        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_images(network, images, dataset_test,indx, threshold, classindicator=-1, refidx=0,nb_test_class=21 ):\n",
    "    predicted=[]\n",
    "    _, w,h,c = dataset_test[0].shape\n",
    "    nbimages=images.shape[0]\n",
    "    nb_display=21\n",
    "    #generates embedings for given images\n",
    "    image_embedings = network.predict(images)\n",
    "    # planton spieces/ classes \n",
    "    classes = load_classes(networkConfig.data_location, networkConfig.extend, networkConfig.min_samples)\n",
    "    #generates embedings for reference images\n",
    "    ref_images = np.zeros((nb_test_class,w,h,c))\n",
    "    for i in range(nb_test_class):\n",
    "        ref_images[i,:,:,:] = dataset_test[i][refidx,:,:,:]\n",
    "    ref_embedings = network.predict(ref_images)\n",
    "        \n",
    "    for i in range(nbimages):\n",
    "        if nbimages>1:\n",
    "            trueclass=i\n",
    "        else:\n",
    "            trueclass=classindicator\n",
    "        \n",
    "        #Prepare the figure\n",
    "        fig=plt.figure(figsize=(50,50))\n",
    "        subplot = fig.add_subplot(1,nb_display+1,1)\n",
    "        subplot.axis(\"off\")\n",
    "        plotidx = 2\n",
    "            \n",
    "        #Draw this image    \n",
    "        plt.imshow(images[i,:,:,0])\n",
    "        subplot.title.set_text(\"Test image\")\n",
    "            \n",
    "        distdtype=[('class', int), ('dist', float)]\n",
    "        dist = np.zeros(nb_test_class, dtype=distdtype)\n",
    "        \n",
    "        #Compute distances\n",
    "        for ref in range(nb_test_class):\n",
    "            #Compute distance between this images and references\n",
    "            dist[ref] = (ref,compute_dist(image_embedings[i,:],ref_embedings[ref,:]))\n",
    "            \n",
    "        #sort\n",
    "        sorted_dist = np.sort(dist, order='dist')\n",
    "        predicted.append(classes[sorted_dist['class'][0]])\n",
    "        #Draw\n",
    "        for j in range(min(21,nb_test_class)):\n",
    "            subplot = fig.add_subplot(1,nb_display+1,plotidx)\n",
    "            plt.imshow(ref_images[sorted_dist['class'][j],:,:,0])\n",
    "            subplot.axis(\"off\")\n",
    "            #Red for sample above threshold\n",
    "            if (sorted_dist['dist'][j] > threshold):\n",
    "                if (trueclass == sorted_dist['class'][j]):\n",
    "                    color = (1,0,0)\n",
    "                    label = \"TRUE\"\n",
    "                else:\n",
    "                    color = (0.5,0,0)\n",
    "                    label = \"Class {0}\".format(sorted_dist['class'][j])\n",
    "            else:\n",
    "                if (trueclass == sorted_dist['class'][j]):\n",
    "                    color = (0, 1, 0)\n",
    "                    label = \"TRUE\"\n",
    "                else:\n",
    "                    color = (0, .5, 0)\n",
    "                    label = \"Class {0}\".format(sorted_dist['class'][j])\n",
    "                \n",
    "            subplot.set_title(\"{0}\\n{1:.3e}\".format(label,sorted_dist['dist'][j]),color=color)\n",
    "            plotidx += 1\n",
    "    return predicted\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_every = 100 # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iter = 5000# No. of training iterations\n",
    "n_val = 100 # how many one- shot tasks to validate on\n",
    "## # #\n",
    "t_start = time.time()\n",
    "n_iteration=0\n",
    "file = open(\"store.txt\", \"w\")\n",
    "for i in range(1, n_iter+1):\n",
    "    #triplets = get_batch_random(batch_size,dataset_train)\n",
    "    triplets=get_batch_hard(200,1,1,base_model,dataset_train)\n",
    "    loss = model.train_on_batch(triplets, None)\n",
    "    #network_train.save_weights(file)\n",
    "    n_iteration += 1\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,loss,n_iteration))\n",
    "        probs,yprob = compute_probs(base_model,x_test_origin[:500,:,:,:],y_test_origin[:500])\n",
    "        #fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "        #draw_roc(fpr, tpr,thresholds,auc)\n",
    "        #draw_interdist(base_model,0,dataset_test)\n",
    "    if i % 1000 == 0:\n",
    "        probs,yprob = compute_probs(base_model,x_test_origin[:500,:,:,:],y_test_origin[:500])\n",
    "        fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "        draw_roc(fpr, tpr,thresholds,auc)\n",
    "        top=1\n",
    "        predicted=prediction1(base_model, x_test_origin, dataset_test,y_test_origin,top, threshold=abs(.007))\n",
    "        Top1_count=np.sum(predicted == y_test_origin)\n",
    "        print(Top1_count)\n",
    "        #base_model.save_weights('{1}3x-temp_weights_{0:08d}.h5'.format(n_iteration,model_path))    \n",
    "#Final save\n",
    "#model.save_weights('{1}3x-temp_weights_{0:08d}.h5'.format(n_iteration,model_path)) \n",
    "ind=0\n",
    "predicted=[]\n",
    "for i in range(1,4):\n",
    "    predicted.append(test_images(base_model, np.expand_dims(x_test_origin[i,:,:,:],axis=0), dataset_test,i,threshold=abs(1)))\n",
    "    ind=ind+ind\n",
    "\n",
    "top=1\n",
    "predicted=prediction1(base_model, x_test_origin, dataset_test,y_test_origin,top, threshold=abs(.007))\n",
    "Top1_count=np.sum(predicted == y_test_origin)\n",
    "\n",
    "top=2\n",
    "predicted=prediction1(base_model, x_test_origin, dataset_test,y_test_origin,top, threshold=abs(1))\n",
    "Top2_count=np.sum(predicted == y_test_origin)\n",
    "\n",
    "top=3\n",
    "predicted=prediction1(base_model, x_test_origin, dataset_test,y_test_origin,top, threshold=abs(1))\n",
    "Top3_count=np.sum(predicted == y_test_origin)\n",
    "\n",
    "top=4\n",
    "predicted=prediction1(base_model, x_test_origin, dataset_test,y_test_origin,top, threshold=abs(1))\n",
    "Top4_count=np.sum(predicted == y_test_origin)\n",
    "\n",
    "top=5\n",
    "predicted=prediction1(base_model, x_test_origin, dataset_test,y_test_origin,top, threshold=abs(1))\n",
    "Top5_count=np.sum(predicted == y_test_origin)\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "objects = ('Top1', 'Top2', 'Top3', 'Top4', 'Top5')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [Top1_count,Top2_count,Top3_count,Top4_count,Top5_count]\n",
    "\n",
    "bar1=plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Number of correct classified species')\n",
    "plt.title('Top accuracy')\n",
    "# Add counts above the two bar graphs\n",
    "for rect in bar1 :\n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width()/2.0, height, '%d ' % ((height*100)/63), ha='center', va='bottom')\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "confusion_matrix=confusion_matrix(y_test_origin,predicted)\n",
    "class_names = load_classes(networkConfig.data_location, networkConfig.extend, networkConfig.min_samples)\n",
    "df_cm = pd.DataFrame(confusion_matrix, index = [i for i in class_names],\n",
    "              columns = [i for i in class_names])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"OrRd\")\n",
    "\n",
    "file = open(\"store.txt\", \"w\")\n",
    "file.write(\" %s,\" %( predicted[:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full evaluation\n",
    "probs,yprob = compute_probs(base_model,x_test_origin,y_test_origin)\n",
    "fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "draw_roc(fpr, tpr,thresholds,auc)\n",
    "draw_interdist(base_model,n_iter,dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "# plot roc curves\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange', label='triploss learning')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC1',dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=0\n",
    "predicted=[]\n",
    "for i in range(0,6):\n",
    "    predicted.append(test_images(base_model, np.expand_dims(x_test_origin[i,:,:,:],axis=0), dataset_test,i,threshold=abs(0.2716)))\n",
    "    ind=ind+ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def buildDataSet1():\n",
    "    # prepare dataset  for train and test\n",
    "    PATH=\"/content/drive/MyDrive/plankton_recognition\"\n",
    "    \n",
    "\ttrain_dir = os.path.join(PATH, 'train')\n",
    "\tvalidation_dir = os.path.join(PATH, 'test')\n",
    "\tBATCH_SIZE = 1050\n",
    "\tIMG_SIZE = (224, 224)\n",
    "\ttrain_dataset = image_dataset_from_directory(train_dir,\n",
    "\t                                             shuffle=False,\n",
    "\t                                            batch_size=BATCH_SIZE,\n",
    "\t                                             image_size=IMG_SIZE)\n",
    "\tvalidation_dataset = image_dataset_from_directory(validation_dir,\n",
    "\t                                                  shuffle=False,\n",
    "\t                                                  batch_size=BATCH_SIZE,\n",
    "\t                                                  image_size=IMG_SIZE)\n",
    "\t\n",
    "\t# train data\n",
    "\tfor images, labels in train_dataset.take(1):\n",
    "        x_train_origin=images\n",
    "        y_train_origin=labels\n",
    "\t# test data\n",
    "\tfor images, labels in validation_dataset.take(1):\n",
    "        x_test_origin=images\n",
    "        y_test_origin=labels\n",
    "\t\n",
    "\tdataset_train = []\n",
    "\tdataset_test = []\n",
    "\t#Sorting images by classes and normalize values 0=>1\n",
    "\tn_classes=21\n",
    "\tclasses = load_classes(networkConfig.data_location, networkConfig.extend, networkConfig.min_samples)\n",
    "\tfor n in range(0,n_classes):\n",
    "        images_class_n = np.asarray([row for idx,row in enumerate(x_train_origin) if class_names[y_train_origin[idx]]==classes[n] ])\n",
    "        dataset_train.append(images_class_n/255)\n",
    "        images_class_n = np.asarray([row for idx,row in enumerate(x_test_origin) if class_names[y_test_origin[idx]]==classes[n]  ])\n",
    "        dataset_test.append(images_class_n/255)\n",
    "    return dataset_train,dataset_test,x_train_origin,y_train_origin,x_test_origin,y_test_origin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction1(network, x_test_origin, dataset_train, test_label,top,threshold,classindicator=-1, refidx=1 ):\n",
    "    predicted=[]\n",
    "    _, w,h,c = dataset_test[0].shape\n",
    "    nbimages=x_test_origin.shape[0]\n",
    "    nb_test_class=len(dataset_train)\n",
    "    # planton spieces/ classes \n",
    "    classes = load_classes(networkConfig.data_location, networkConfig.extend, networkConfig.min_samples)\n",
    "    nb_display=len(classes)\n",
    "    #generates embedings for reference images\n",
    "    ref_images = np.zeros((nb_test_class,w,h,c))\n",
    "    for i in range(nb_test_class):\n",
    "        ref_images[i,:,:,:] = dataset_train[i][refidx,:,:,:]\n",
    "    ref_embedings = network.predict(ref_images) \n",
    "    \n",
    "    for i in range(nbimages):\n",
    "        #generates embedings for given images\n",
    "        image_embedings = network.predict(np.expand_dims(x_test_origin[i,:,:,:],axis=0))\n",
    "        distdtype=[('class', int), ('dist', float)]\n",
    "        dist = np.zeros(nb_test_class, dtype=distdtype)        \n",
    "        #Compute distances\n",
    "        for ref in range(nb_test_class):\n",
    "            #Compute distance between this images and references\n",
    "            dist[ref] = (ref,compute_dist(image_embedings[:],ref_embedings[ref,:]))  \n",
    "            #dist[ref] = (ref,euclidean_distance(image_embedings[:],ref_embedings[ref,:]))\n",
    "        #sort\n",
    "        sorted_dist = np.sort(dist, order='dist')\n",
    "        found=False\n",
    "\n",
    "        for a in range(top):\n",
    "            if (test_label[i]==classes[sorted_dist['class'][a]]):\n",
    "                predicted.append(classes[sorted_dist['class'][a]])\n",
    "                found=True;\n",
    "                c=c+1\n",
    "                break;\n",
    "        if(found==False):\n",
    "            predicted.append(classes[sorted_dist['class'][0]])\n",
    "    \n",
    "    print(c)        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "import datetime\n",
    "for i in range(1, n_iter+1):\n",
    "    microtask_start =time.time() \n",
    "    triplets=get_batch_hard1(200,1,1,base_model,dataset_train)\n",
    "    #triplets,quadruplets = get_batch_hardOptimized(100,16,16,network3,network4,metric_network4, dataset_train)\n",
    "    timetogetbatch = time.time()-microtask_start\n",
    "    microtask_start =time.time() \n",
    "    loss1 = model.train_on_batch(triplets, None)\n",
    "    timebatch3 = time.time()-microtask_start\n",
    "    n_iteration += 1\n",
    "    if i % log_every == 0:\n",
    "        wandb.log({'loss3x': loss1,'loss4x': loss2}, step=n_iteration)\n",
    "    if i % evaluate_every == 0:\n",
    "        elapsed_minutes = (time.time()-t_start)/60.0\n",
    "        rate = i/elapsed_minutes \n",
    "        #eta = datetime.now()+timedelta(minutes=(n_iter-i)/rate)\n",
    "        #eta = eta + timedelta(hours=3) #finnish time\n",
    "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,loss,n_iteration))\n",
    "        base_model.save_weights('{1}3x-temp_weights_{0:08d}.h5'.format(n_iteration,model_path))    \n",
    "#Final save\n",
    "network3_train.save_weights('{1}3x-temp_weights_{0:08d}.h5'.format(n_iteration,model_path))  \n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_images1(network, images, dataset_test,indx, threshold, classindicator=-1, refidx=0,nb_test_class=21 ):\n",
    "    _, w,h,c = dataset_test[0].shape\n",
    "    nbimages=images.shape[0]\n",
    "    nb_display=21\n",
    "    #generates embedings for given images\n",
    "    image_embedings = network.predict(images)\n",
    "    # planton spieces/ classes \n",
    "    classes = load_classes(networkConfig.data_location, networkConfig.extend, networkConfig.min_samples)\n",
    "    #generates embedings for reference images\n",
    "    ref_images = np.zeros((nb_test_class,w,h,c))\n",
    "    for i in range(nb_test_class):\n",
    "        ref_images[i,:,:,:] = dataset_test[i][refidx,:,:,:]\n",
    "    ref_embedings = network.predict(ref_images)\n",
    "            \n",
    "    for i in range(nbimages):\n",
    "        if nbimages>1:\n",
    "            trueclass=i\n",
    "        else:\n",
    "            trueclass=classindicator\n",
    "        \n",
    "        #Prepare the figure\n",
    "        fig=plt.figure(figsize=(50,50))\n",
    "        subplot = fig.add_subplot(1,nb_display+1,1)\n",
    "        subplot.axis(\"off\")\n",
    "        plotidx = 2\n",
    "            \n",
    "        #Draw this image    \n",
    "        plt.imshow(images[i,:,:,0])\n",
    "        subplot.title.set_text(\"Test image\")\n",
    "            \n",
    "        distdtype=[('class', int), ('dist', float)]\n",
    "        dist = np.zeros(nb_test_class, dtype=distdtype)\n",
    "        \n",
    "        #Compute distances\n",
    "        for ref in range(nb_test_class):\n",
    "            #Compute distance between this images and references\n",
    "            dist[ref] = (ref,compute_dist(image_embedings[i,:],ref_embedings[ref,:]))\n",
    "            \n",
    "        #sort\n",
    "        sorted_dist = np.sort(dist, order='dist')\n",
    "        \n",
    "        #Draw\n",
    "        for j in range(min(21,nb_test_class)):\n",
    "            subplot = fig.add_subplot(1,nb_display+1,plotidx)\n",
    "            plt.imshow(ref_images[sorted_dist['class'][j],:,:,0])\n",
    "            subplot.axis(\"off\")\n",
    "            #Red for sample above threshold\n",
    "            if (sorted_dist['dist'][j] > threshold):\n",
    "                if (trueclass == sorted_dist['class'][j]):\n",
    "                    color = (1,0,0)\n",
    "                    label = \"TRUE\"\n",
    "                else:\n",
    "                    color = (0.5,0,0)\n",
    "                    label = \"Class {0}\".format(sorted_dist['class'][j])\n",
    "            else:\n",
    "                if (trueclass == sorted_dist['class'][j]):\n",
    "                    color = (0, 1, 0)\n",
    "                    label = \"TRUE\"\n",
    "                else:\n",
    "                    color = (0, .5, 0)\n",
    "                    label = \"Class {0}\".format(sorted_dist['class'][j])\n",
    "                \n",
    "            subplot.set_title(\"{0}\\n{1:.3e}\".format(label,sorted_dist['dist'][j]),color=color)\n",
    "            plotidx += 1   \n",
    "\n",
    "'''\n",
    "    Evaluate some pictures vs some samples in the test set\n",
    "        image must be of shape(1,w,h,c)\n",
    "    Returns\n",
    "        scores : resultat des scores de similaritÃ©s avec les images de base => (N)\n",
    "'''\n",
    "def DrawTestImage(network, images, dataset_test, index,refidx=0,nb_test_class=21):\n",
    "    N=4\n",
    "    _, w,h,c = dataset_test[0].shape\n",
    "    nbimages=images.shape[0]\n",
    "    classes = load_classes(networkConfig.data_location, networkConfig.extend, networkConfig.min_samples)\n",
    "    #generates embedings for given images\n",
    "    image_embedings = network.predict(images)\n",
    "    \n",
    "    #generates embedings for reference images\n",
    "    ref_images = np.zeros((nb_classes,w,h,c))\n",
    "    for i in range(nb_classes):\n",
    "        ref_images[i,:,:,:] = dataset_test[i][refidx,:,:,:]\n",
    "    ref_embedings = network.predict(ref_images)\n",
    "            \n",
    "    for i in range(nbimages):\n",
    "        #Prepare the figure\n",
    "        fig=plt.figure(figsize=(50,50))\n",
    "        subplot = fig.add_subplot(1,nb_classes+1,1)\n",
    "        subplot.axis(\"off\")\n",
    "        plotidx = 2\n",
    "            \n",
    "        #Draw this image    \n",
    "        plt.imshow(images[i,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
    "        subplot.title.set_text(classes[index])\n",
    "            \n",
    "        for ref in range(nb_classes):\n",
    "            #Compute distance between this images and references\n",
    "            dist = compute_dist(image_embedings[i,:],ref_embedings[ref,:])\n",
    "            #Draw\n",
    "            subplot = fig.add_subplot(1,nb_classes+1,plotidx)\n",
    "            subplot.axis(\"off\")\n",
    "            plt.imshow(ref_images[ref,:,:,0])\n",
    "            subplot.title.set_text((\"Class {0}\\n{1:.3e}\".format(ref,dist)))\n",
    "            plotidx += 1\n",
    "    \n",
    "# Trainning of the model \n",
    "\n",
    "def prediction1(network, x_test_origin, dataset_test, test_label,top,threshold,classindicator=-1, refidx=0,nb_test_class=50 ):\n",
    "    predicted=[]\n",
    "    _, w,h,c = dataset_test[0].shape\n",
    "    nbimages=x_test_origin.shape[0]\n",
    "    nb_display=50\n",
    "    # planton spieces/ classes \n",
    "    classes = load_classes(networkConfig.data_location, networkConfig.extend, networkConfig.min_samples)\n",
    "    nb_display=len(classes)\n",
    "    nb_test_class=len(classes)\n",
    "    #generates embedings for reference images\n",
    "    ref_images = np.zeros((nb_test_class,w,h,c))\n",
    "    for i in range(nb_test_class):\n",
    "        ref_images[i,:,:,:] = dataset_test[i][refidx,:,:,:]\n",
    "    ref_embedings = network.predict(ref_images)   \n",
    "    c=0\n",
    "    for i in range(0,nbimages):\n",
    "        #generates embedings for given images\n",
    "        image_embedings = network.predict(np.expand_dims(x_test_origin[i,:,:,:],axis=0))\n",
    "        if nbimages>1:\n",
    "            trueclass=i\n",
    "        else:\n",
    "            trueclass=classindicator\n",
    "        distdtype=[('class', int), ('dist', float)]\n",
    "        dist = np.zeros(nb_test_class, dtype=distdtype)        \n",
    "        #Compute distances\n",
    "        for ref in range(nb_test_class):\n",
    "            #Compute distance between this images and references\n",
    "            dist[ref] = (ref,compute_dist(image_embedings[:],ref_embedings[ref,:]))          \n",
    "        #sort\n",
    "        sorted_dist = np.sort(dist, order='dist')\n",
    "        found=False\n",
    "\n",
    "        for a in range(0,top):\n",
    "            if (test_label[i]==classes[sorted_dist['class'][a]]):\n",
    "                predicted.append(classes[sorted_dist['class'][a]])\n",
    "                found=True;\n",
    "                c=c+1\n",
    "                break;\n",
    "        if(found==False):\n",
    "            predicted.append(classes[sorted_dist['class'][0]])\n",
    "    print(c)        \n",
    "    return predicted    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=[]\n",
    "time_taken=[]\n",
    "for k in range(1,6):\n",
    "    topac=[]\n",
    "    timeacc=[]\n",
    "    for i in range(1,7):\n",
    "        [predicted,time_t]=classifier(base_model, x_test_origin, dataset_train,y_test_origin,i,k)\n",
    "        count=np.sum(predicted == y_test_origin)\n",
    "        topac.append(count)\n",
    "        timeacc.append(time_t)\n",
    "    correct.append(topac)\n",
    "    time_taken.append(timeacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(network, x_test_origin, dataset_train,test_label,refidx,top):\n",
    "    t_start = time.time()\n",
    "    predicted=[]\n",
    "    _, w,h,c = dataset_train[0].shape\n",
    "    nbimages=x_test_origin.shape[0]\n",
    "    # planton spieces/ classes \n",
    "    classes = load_classes(networkConfig.data_location, networkConfig.extend, networkConfig.min_samples)\n",
    "    nb_display=len(classes)\n",
    "    nb_test_class=len(dataset_train)\n",
    "    for i in range(0,nbimages):\n",
    "        distdtype=[('class', int), ('dist', float)]\n",
    "        dist1 = np.zeros(refidx, dtype=distdtype)\n",
    "        #generates embedings for given images\n",
    "        c=0;\n",
    "        image_embedings = network.predict(np.expand_dims(x_test_origin[i,:,:,:],axis=0))\n",
    "        for k in range(0,refidx):\n",
    "            ref_images = np.zeros((nb_test_class,w,h,3))\n",
    "            for j in range(0,nb_test_class):\n",
    "                ref_images[j,:,:,:] = dataset_train[j][k,:,:,:]\n",
    "                \n",
    "            ref_embedings = network.predict(ref_images)  \n",
    "            #Compute distances\n",
    "            distdtype=[('class', int), ('dist', float)]\n",
    "            dist = np.zeros(nb_test_class, dtype=distdtype)\n",
    "            for ref in range(0,nb_test_class):\n",
    "                #Compute distance between this images and references\n",
    "                dist[ref] = (ref,compute_dist(image_embedings[:],ref_embedings[ref,:]))\n",
    "                #dist[ref] = (ref,euclidean_distance(image_embedings[:],ref_embedings[ref,:]))\n",
    "            #sort\n",
    "            sorted_dist = np.sort(dist, order='dist')\n",
    "            found=False\n",
    "            for a in range(0,top):\n",
    "                if (test_label[i]==classes[sorted_dist['class'][a]]):\n",
    "                    predicted.append(classes[sorted_dist['class'][a]])\n",
    "                    found=True;\n",
    "                    c=c+1\n",
    "                    break;\n",
    "            if(found==True):\n",
    "                break;\n",
    "            else:\n",
    "                dist1[k]=(sorted_dist['class'][0],sorted_dist['dist'][0])\n",
    "        if(c==0):\n",
    "            sorted_dist1 = np.sort(dist1, order='dist')\n",
    "            predicted.append(classes[sorted_dist1['class'][0]])\n",
    "    timeT=((time.time()-t_start)/60.0)\n",
    "    return predicted, timeT  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
